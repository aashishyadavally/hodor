"""Processes user query, either by text or image to retrieve relevant
images from the image database.
"""
import json
import heapq
import shutil
import pickle
import operator
from pathlib import Path

import numpy as np

import matplotlib.pyplot as plt

import cv2

from rubrix import pathfinder
from rubrix.index.descriptors import TARGET_SIZE
from rubrix.index.encodings import MODULE_URL
from rubrix.image.extract import extract_image_descriptors
from rubrix.image.detect import get_yolo_net, get_labels, detect_objects
from rubrix.utils import extract_features, get_similar_words, cosine_distance, dot_product


class SearchResultObject:
    def __init__(self, name, index, path_to_image, path_to_embed, score):
        """Data structure useful to track results generated by user query,
        containing image information such as file name, parameter ``index``,
        useful to retrieve image path.path to image, semantic score with
        user query.

        Comparison operators for ``SearchResultObject`` is determined based on
        the semantic similarity score of the caption corresponding to the
        result image with the user query.

        Parameters:
        -----------
            name (str):
                Name of image.
            index (int):
                Image index.
            path_to_image (pathlib.Path):
                Path to image.
            path_to_embed (pathlib.Path):
                Path to .npy sentence embedding.
            score (float):
                Semantic similarity score with given text.
        """
        self.name = name
        self.index = index
        self.path_to_image = path_to_image
        self.path_to_embed = path_to_embed
        self.score = score

    def __key(self):
        return self.score

    def __eq__(self, other):
        if isinstance(other, self.__class__) and \
           self.__key() == other.__key():
            return True
        return False

    def __gt__(self, other):
        if isinstance(other, self.__class__) and \
           self.__key() > other.__key():
            return True
        return False

    def __lt__(self, other):
        if isinstance(other, self.__class__) and \
           self.__key() < other.__key():
            return True
        return False

    def __hash__(self):
        return hash(self.__key())


class ReverseSearchResultObject(SearchResultObject):
    def __init__(self, name, path_to_image, score):
        """Data structure useful to track results generated by user-uploaded
        image, containing image information such as file name, path to image,
        similarity score between feature vectors for result and original image.

        Comparison operators for ``ReverseSearchResultObject`` is determined
        based on the similarity score of the image descriptor corresponding to
        the result image with that uploaded by the user.

        Parameters:
        -----------
            name (str):
                Name of image.
            path_to_image (pathlib.Path):
                Path to image.
            score (float):
                Similarity score with given text.
        """
        self.name = name
        self.path_to_image = path_to_image
        self.score = score


def query_by_text(text, model, save=False):
    """Processes text queries to retrieve relevant images from database.

    Arguments:
    ----------
        text (str):
            User-input text query.
        model (tensorflow.saved_model):
            Universal sentence encoder (large) tensorflow saved model.
        save (bool):
            If True, save predictions to /assets/predictions.

    Returns:
    --------
        results (list of pathlib.Path objects):
            List of paths to images retrieved for user query.
    """
    features = extract_features(text)

    keys = [get_similar_words(feature, 'coco.names', n=2) \
            for feature in features]

    keys = [word for similar_words in keys for word in similar_words]

    index_path = pathfinder.get('assets', 'index.json')

    with open(index_path, 'r') as index_file:
        index = json.load(index_file)       

    # We need to perform membership test to check if a given image
    # identifier is already a part of ``image_ids``. 
    # Membership tests in sets is O(1) as opposed to that in lists,
    # which is O(n). Hence, the former is the preferred data structure
    # for ``image_ids``.
    image_paths = set([])

    for key in keys:
        items = set(index[key])
        image_paths |= items
        
    embeddings_path = pathfinder.get('assets', 'imageEmbeddingLocations.json')

    with open(embeddings_path, 'r') as embeddings_file:
        embeddings = json.load(embeddings_file)

    array = model([text]).numpy()[0]

    results = []

    for index, path in enumerate(image_paths):
        iid = Path(path).name
        embeddings_paths = embeddings[iid]

        similarity_scores = []
        for embedding_path in embeddings_paths:
            other_array = np.load(embedding_path)
            similarity_scores.append(dot_product(array, other_array))
        max_idx = similarity_scores.index(max(similarity_scores))

        results.append(SearchResultObject(
                        name=iid,
                        index=index,
                        path_to_image=path,
                        path_to_embed=embeddings_paths[max_idx],
                        score=similarity_scores[max_idx],
                      )
        )

    # Using heaps to extract N largest results from a list of n elements
    # is recommended, as the time complexity to do so is O(n * logN), which
    # is approximately O(n) if N is relatively small.
    results = heapq.nlargest(5, results)
    results = [result.path_to_image for result in results]

    if save:
        # Save predictions to /assets/predictions.
        save_predictions(results)

    return results


def query_by_image_captions(image_path, model, save=True):
    """Processes user-uploaded image to retrieve similar images from database.

    First, an image caption is generated for the user-uploaded image, and
    the generated caption is passed as a parameter to the :method:
    ``query_by_text``.

    Arguments:
    ----------
        image_path (numpy.ndarray):
            Path for user-uploaded image, for reverse-image search.
        model (tensorflow.saved_model):
            Universal sentence encoder (large) tensorflow saved model.
        save (bool):
            If True, save predictions to /assets/predictions.

    Returns:
    --------
        results (list of pathlib.Path objects):
            List of paths to images retrieved for user query.
    """
    pass


def query_by_image_objects(image_path, weights_path, cfg_path, names_path, 
                           confidence_threshold=0.5, save=False):
    """Processes user-uploaded image to retrieve similar images from database.

    First, all the objects in the image are detected using the :method:
    ``rubrix.images.detect.detect_objects``. Next, the image descriptor array
    for the user-uploaded image is compared with that of all pruned images so
    as to retrieve the top-5 results.

    Arguments:
    ----------
        image_path (numpy.ndarray):
            Path for user-uploaded image, for reverse-image search.
        weights_path (pathlib.Path):
            Path to YOLOv4 pretrained weights file.
        cfg_path (pathlib.Path):
            Path to darknet configuration file.
        names_path (pathlib.Path):
            Path to darknet names file.
        save (bool):
            If True, save predictions to /assets/predictions.

    Returns:
    --------
        results (list of pathlib.Path objects):
            List of paths to images retrieved for user query.
    """
    # Retrieve image descriptor vector for user-uploaded image.
    array = extract_image_descriptors(image_path, 'inception', TARGET_SIZE)
    array = array.reshape(-1)

    # Retrieve YOLOv4 model related variables to detect objects in an image.
    net = get_yolo_net(cfg_path, weights_path)
    labels = get_labels(names_path)
    image = cv2.imread(str(image_path))
    objects = detect_objects(net, labels, image, confidence_threshold)    

    index_path = pathfinder.get('assets', 'index.json')
    with open(index_path, 'r') as json_file:
        index = json.load(json_file)

    paths_to_images = set([])
    for object in objects:
        paths_to_images |= set(index[object])

    descriptors_path = pathfinder.get('assets', 'data', 'descriptors')

    results = []
    for path in paths_to_images:
        path = Path(path)
        other_array = np.load(descriptors_path / f'{path.stem}.npy')
        score = dot_product(array, other_array)
        results.append(ReverseSearchResultObject(
                        name=path.name,
                        path_to_image=path,
                        score=score,
                      )
        )

    # Using heaps to extract N largest results from a list of n elements
    # is recommended, as the time complexity to do so is O(n * logN), which
    # is approximately O(n) if N is relatively small.
    results = heapq.nlargest(5, results)
    results = [result.path_to_image for result in results]

    if save:
        # Save predictions to /assets/predictions.
        save_predictions(results)

    return results


def save_predictions(results):
    """Saves predictions in /assets/predictions.

    Arguments:
    ----------
        results (list of pathlib.Path objects):
            List of results returned for user query / upload.
    """
    predictions_path = pathfinder.get('assets', 'predictions')

    if predictions_path.is_dir():
        shutil.rmtree(str(predictions_path))
    predictions_path.mkdir()

    for _id, path in enumerate(results):
        dest_path = predictions_path / f"{_id + 1}.jpg"
        shutil.copy(str(path), str(dest_path))
