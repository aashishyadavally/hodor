"""Processes user query, either by text or image to retrieve relevant
images from the image database.
"""
import json
import heapq
import shutil
import pickle
import operator
from pathlib import Path

import numpy as np

import matplotlib.pyplot as plt

from rubrix import pathfinder
from rubrix.globals import TARGET_SIZE
from rubrix.index.encodings import MODULE_URL
from rubrix.images.extract import extract_image_descriptors
from rubrix.utils import extract_features, get_similar_words, cosine_distance, dot_product


class SearchResultObject:
    def __init__(self, name, index, path_to_image, path_to_embed, score):
        """Data structure useful to track results generated by user query,
        containing image information such as file name, parameter ``index``,
        useful to retrieve image path.path to image, semantic score with
        user query.

        Comparison operators for ``SearchResultObject`` is determined based on
        the semantic similarity score of the caption corresponding to the
        result image with the user query.

        Parameters:
        -----------
            name (str):
                Name of image.
            index (int):
                Image index.
            path_to_image (pathlib.Path):
                Path to image.
            path_to_embed (pathlib.Path):
                Path to .npy sentence embedding.
            score (float):
                Semantic similarity score with given text.
        """
        self.name = name
        self.index = index
        self.path_to_image = path_to_image
        self.path_to_embed = path_to_embed
        self.score = score

    def __key(self):
        return self.score

    def __eq__(self, other):
        if isinstance(other, self.__class__) and \
           self.__key() == other.__key():
            return True
        return False

    def __gt__(self, other):
        if isinstance(other, self.__class__) and \
           self.__key() > other.__key():
            return True
        return False

    def __lt__(self, other):
        if isinstance(other, self.__class__) and \
           self.__key() < other.__key():
            return True
        return False

    def __hash__(self):
        return hash(self.__key())


class ReverseSearchResultObject(SearchResultObject):
    def __init__(self, name, path_to_image, score):
        """Data structure useful to track results generated by user query,
        containing image information such as file name, parameter ``index``,
        useful to retrieve image path.path to image, semantic score with
        user query.

        Comparison operators for ``SearchResultObject`` is determined based on
        the semantic similarity score of the caption corresponding to the
        result image with the user query.

        Parameters:
        -----------
            name (str):
                Name of image.
            path_to_image (pathlib.Path):
                Path to image.
            score (float):
                Semantic similarity score with given text.
        """
        self.name = name
        self.path_to_image = path_to_image
        self.score = score


def query_by_text(text, model, save=True):
    """Processes text queries to retrieve relevant images from database.

    Arguments:
    ----------
        text (str):
            User-input text query.
        model (tensorflow.saved_model):
            Universal sentence encoder (large) tensorflow saved model.
        save (bool):
            If True, save predictions to /assets/predictions.

    Returns:
    --------
        results (list of pathlib.Path objects):
            List of paths to images retrieved for user query.
    """
    features = extract_features(text)

    keys = [get_similar_words(feature, 'coco.names', n=2) \
            for feature in features]

    keys = [word for similar_words in keys for word in similar_words]

    index_path = pathfinder.get('assets', 'index.json')

    with open(index_path, 'r') as index_file:
        index = json.load(index_file)       

    # We need to perform membership test to check if a given image
    # identifier is already a part of ``image_ids``. 
    # Membership tests in sets is O(1) as opposed to that in lists,
    # which is O(n). Hence, the former is the preferred data structure
    # for ``image_ids``.
    image_paths = set([])

    for key in keys:
        items = set(index[key])
        image_paths |= items
        
    embeddings_path = pathfinder.get('assets', 'imageEmbeddingLocations.json')

    with open(embeddings_path, 'r') as embeddings_file:
        embeddings = json.load(embeddings_file)

    array = model([text]).numpy()[0]

    results = []

    for index, path in enumerate(image_paths):
        iid = Path(path).name
        embeddings_paths = embeddings[iid]

        similarity_scores = []
        for embedding_path in embeddings_paths:
            other_array = np.load(embedding_path)
            similarity_scores.append(dot_product(array, other_array))
        max_idx = similarity_scores.index(max(similarity_scores))

        results.append(SearchResultObject(
                        name=iid,
                        index=index,
                        path_to_image=path,
                        path_to_embed=embeddings_paths[max_idx],
                        score=similarity_scores[max_idx],
                      )
        )

    # Using heaps to extract N largest results from a list of n elements
    # is recommended, as the time complexity to do so is O(n * logN), which
    # is approximately O(n) if N is relatively small.
    results = heapq.nlargest(5, results)
    results = [result.path_to_image for result in results]

    if save:
        # Save predictions to /assets/predictions.
        save_predictions(results)

    return results


def query_by_image_clusters(image_path, model, save=True):
    """Processes user-uploaded image to retrieve similar images from database.

    Uses :method: ``rubrix.images.extract.extract_image_descriptors`` to
    extract feature vector for the user-uploaded image. Furthermore, the
    cluster that this image belongs to is determined, and the top-5 images
    are returned as results.

    Arguments:
    ----------
        image_path (numpy.ndarray):
            Path for user-uploaded image, for reverse-image search.
        model (tensorflow.saved_model):
            Universal sentence encoder (large) tensorflow saved model.
        save (bool):
            If True, save predictions to /assets/predictions.

    Returns:
    --------
        results (list of pathlib.Path objects):
            List of paths to images retrieved for user query.
    """
    features = extract_image_descriptors(image_path, 'inception', TARGET_SIZE)

    scaler_path = pathfinder.get('assets', 'scaler')
    mean = np.load(scaler_path / 'mean.npy')
    std = np.load(scaler_path / 'std.npy')

    features = (features - mean) / std

    pca_model_path = pathfinder.get('assets', 'models', 'pca_model.pkl')
    with open(pca_model_path, 'rb') as pickle_file:
        pca_model = pickle.load(pickle_file)

    features_reduced = pca_model.transform([features])
    array = features_reduced.reshape(-1)

    cluster_centers_path = pathfinder.get('assets', 'data', 'cluster_centers')

    idx, _ = max(enumerate([dot_product(array, np.load(path)) \
                            for path in cluster_centers_path.iterdir()]),
                 key=operator.itemgetter(1))

    cluster_index_path = pathfinder.get('assets', 'cluster_index.json')
    with open(cluster_index_path, 'r') as cluster_file:
        cluster_index = json.load(cluster_file)

    results = []

    for other_dict in cluster_index[f'cluster{idx}']:
        other = np.load(other_dict['path_to_array'])
        path_to_image = other_dict['path_to_image']
        score = dot_product(features_reduced, other)
        results.append(ReverseSearchResultObject(
                        name=other_dict['filename'],
                        path_to_image=path_to_image,
                        score=score,
                      )
        )

    # Using heaps to extract N largest results from a list of n elements
    # is recommended, as the time complexity to do so is O(n * logN), which
    # is approximately O(n) if N is relatively small.
    results = heapq.nlargest(5, results)
    results = [result.path_to_image for result in results]

    if save:
        # Save predictions to /assets/predictions.
        save_predictions(results)

    return results

def query_by_image_captions(image_path, model, save=True):
    """Processes user-uploaded image to retrieve similar images from database.

    First, an image caption is generated for the user-uploaded image, and
    the generated caption is passed as a parameter to the :method:
    ``query_by_text``.

    Arguments:
    ----------
        image_path (numpy.ndarray):
            Path for user-uploaded image, for reverse-image search.
        model (tensorflow.saved_model):
            Universal sentence encoder (large) tensorflow saved model.
        save (bool):
            If True, save predictions to /assets/predictions.

    Returns:
    --------
        results (list of pathlib.Path objects):
            List of paths to images retrieved for user query.
    """
    pass


def save_predictions(results):
    """Saves predictions in /assets/predictions.

    Arguments:
    ----------
        results (list of pathlib.Path objects):
            List of results returned for user query / upload.
    """
    predictions_path = pathfinder.get('assets', 'predictions')

    if predictions_path.is_dir():
        shutil.rmtree(str(predictions_path))
    predictions_path.mkdir()

    for _id, path in enumerate(results):
        dest_path = predictions_path / f"{_id + 1}.png"
        shutil.copy(str(path), str(dest_path))
